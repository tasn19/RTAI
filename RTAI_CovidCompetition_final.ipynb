{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RTAI_CovidCompetition_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j7QBde8Kpb89",
        "-Dn0t4V2pgXX",
        "iVIpbxhi9m8T",
        "oqR5agGf86Rz",
        "86qqKTh2kqXT",
        "MWYzA_8H8-4b",
        "lLw0FO1aaVpC",
        "Epk8CozA86Xa",
        "xBnFkcJ3AvVV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasn19/RTAI/blob/main/RTAI_CovidCompetition_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XirbG2Um7yfA"
      },
      "source": [
        "# **AI Against Covid 19 Competition**\n",
        "competition details: https://r7.ieee.org/montreal-sight/ai-against-covid-19/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7QBde8Kpb89"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8PJ_FY_1AUx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTh_eXpCFVjV"
      },
      "source": [
        "# To copy the data to colab memory, run everytime the runtime is restarted\n",
        "!unzip \"/content/gdrive/MyDrive/RTAI-data/archive.zip\" -d \"/content/archive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieeZ2k-sa4lf"
      },
      "source": [
        "# To see gpu allocation\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dn0t4V2pgXX"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL-Anx--FXg_"
      },
      "source": [
        "import os, glob\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TODO: mix train and test for the final training(?)\n",
        "\n",
        "# data path in drive\n",
        "# train_images = \"/content/gdrive/MyDrive/RTAI-data/archive/train/\"\n",
        "# train_metadata = \"/content/gdrive/MyDrive/RTAI-data/archive/train.txt\"\n",
        "# test_images = \"/content/gdrive/MyDrive/RTAI-data/archive/test/\"\n",
        "# test_metadata = \"/content/gdrive/MyDrive/RTAI-data/archive/test.txt\"\n",
        "\n",
        "# data path in colab\n",
        "train_images_path = \"/content/archive/train/\"\n",
        "train_metadata_path = \"/content/archive/train.txt\"\n",
        "test_images_path = \"/content/archive/test/\"\n",
        "test_metadata_path = \"/content/archive/test.txt\"\n",
        "competition_test_path = \"/content/archive/competition_test/\"\n",
        "\n",
        "val_ratio = 0.1\n",
        "image_size = 299\n",
        "\n",
        "label_dict = {'positive': 1, 'negative': 0}\n",
        "\n",
        "class CovidDataSet(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = None\n",
        "        if annotations_file is not None:\n",
        "            self.img_labels = pd.read_csv(annotations_file, delimiter = \" \", names=['patient id', 'filename', 'class', 'data source'])\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        if self.img_labels is not None:\n",
        "            self.len = len(self.img_labels)\n",
        "        else:\n",
        "            self.len = sum([len(glob.glob(img_dir+s)) for s in ['*.jpg', '*.png', '*.jpeg']])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
        "        # image = read_image(img_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = label_dict[self.img_labels.iloc[idx, 2]]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class MyTopCropTransform:\n",
        "    \"\"\"\n",
        "    crop the top <ratio> of the image \n",
        "    \"\"\"\n",
        "    def __init__(self, ratio):\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def __call__(self, x):\n",
        "        c, h, w = x.shape\n",
        "        top = int(h*self.ratio)\n",
        "        return transforms.functional.crop(x, top, 0, h-top, w)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    MyTopCropTransform(0.08), \n",
        "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)),\n",
        "    # transforms.Resize(size=image_size), transforms.CenterCrop(image_size), #keeps the aspect ratio\n",
        "    transforms.Resize(size=(image_size,image_size)) #doesn't keep the aspect ratio\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    MyTopCropTransform(0.08), \n",
        "    # transforms.Resize(size=image_size), transforms.CenterCrop(image_size), # keeps the aspect ratio, crops the image\n",
        "    transforms.Resize(size=(image_size,image_size)) # doesn't keep the aspect ratio\n",
        "])\n",
        "\n",
        "# TODO: try rescale and crop\n",
        "# TODO: try black and white\n",
        "# TODO: normalize to -1 and 1\n",
        "\n",
        "train_dataset = CovidDataSet(train_metadata_path, train_images_path, train_transform)\n",
        "val_dataset = CovidDataSet(train_metadata_path, train_images_path, test_transform)\n",
        "test_dataset = CovidDataSet(test_metadata_path, test_images_path, test_transform)\n",
        "# competition_test_dataset = CovidDataSet(None, competition_test_path, None, test_transform)\n",
        "\n",
        "\n",
        "# splitting the train dataset to train and validation\n",
        "train_indices, val_indices = train_test_split(range(len(train_dataset)), test_size = val_ratio)\n",
        "train_dataset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "\n",
        "# TO TAKE RANDOM SUBSET OF DATA\n",
        "# torch.manual_seed(1)\n",
        "# train_indices = torch.randperm(len(train_dataset)).tolist()\n",
        "# val_indices = torch.randperm(len(val_dataset)).tolist()\n",
        "# test_indices = torch.randperm(len(test_dataset)).tolist()\n",
        "\n",
        "# # take the first {num} items\n",
        "# train_dataset = torch.utils.data.Subset(train_dataset, train_indices[:100]) # was [:-1000]\n",
        "# # take the last {num} items\n",
        "# val_dataset = torch.utils.data.Subset(val_dataset, test_indices[:100]) # was [-1000:]\n",
        "# # take the last {num} items\n",
        "# test_dataset = torch.utils.data.Subset(test_dataset, test_indices[:100]) # was [-1000:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVIpbxhi9m8T"
      },
      "source": [
        "# # Temp data reading and augmentation test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaSm88Jk9pR2"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "path = \"/content/archive/train/\"\n",
        "im_path = os.path.join(path,(os.listdir(path))[10])\n",
        "image_size = 500\n",
        "\n",
        "im_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    MyTopCropTransform(0.08), \n",
        "    # transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)),\n",
        "    # transforms.Resize(size=image_size), transforms.CenterCrop(image_size), #keeps the aspect ratio\n",
        "    transforms.Resize(size=(image_size,image_size)), #doesn't keep the aspect ratio\n",
        "    # transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "image = Image.open(im_path).convert(\"RGB\")\n",
        "image_tensor = im_transforms(image)\n",
        "\n",
        "plt.subplot(1,2,1).imshow(image)\n",
        "plt.title(\"original\")\n",
        "plt.subplot(1,2,2).imshow(image_tensor.permute(1,2,0))\n",
        "plt.title(\"transformed\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# test_paths = [im_path]\n",
        "\n",
        "# png, jpeg, jpg = True, True, True\n",
        "# for impath in os.listdir(path):\n",
        "#   filename, file_extension = os.path.splitext(impath)\n",
        "#   if file_extension == \".png\" and png:\n",
        "#     test_paths.append(os.path.join(path,impath))\n",
        "#     png = False\n",
        "#   if file_extension == \".jpeg\" and jpeg:\n",
        "#     test_paths.append(os.path.join(path,impath))\n",
        "#     jpeg = False\n",
        "#   if file_extension == \".jpg\" and jpg:\n",
        "#     test_paths.append(os.path.join(path,impath))\n",
        "#     jpg = False\n",
        "#   if png and jpeg and jpg:\n",
        "#     break\n",
        "\n",
        "# for im_path in test_paths:\n",
        "#   image = Image.open(im_path).convert(\"L\")\n",
        "#   image_tensor = transforms.ToTensor()(image)\n",
        "#   print(\"size: {}, bands: {}\".format(image.size, image.getbands()))\n",
        "#   print(\"tensor size: {}\".format(image_tensor.size()))\n",
        "#   print(\"max {},  min {}, some pixel {}\".format(torch.max(image_tensor), torch.min(image_tensor), image_tensor[0,400,400]))\n",
        "#   plt.subplot(1,2,1).imshow(image, cmap=plt.cm.gray)\n",
        "#   plt.title(\"original\")\n",
        "#   plt.subplot(1,2,2).imshow(image_tensor.permute(1,2,0).squeeze(), cmap=plt.cm.gray)\n",
        "#   plt.title(\"transformed\")\n",
        "#   plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqR5agGf86Rz"
      },
      "source": [
        "# Model Resnet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7n3QUniztxM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152, resnext50_32x4d, resnext101_32x8d, wide_resnet50_2, wide_resnet101_2\n",
        "\n",
        "resnet_models = {'resnet18': resnet18, \n",
        "                 'resnet34': resnet34, \n",
        "                 'resnet50': resnet50, \n",
        "                 'resnet101': resnet101,\n",
        "                 'resnet152': resnet152,\n",
        "                 'resnext50_32x4d': resnext50_32x4d, \n",
        "                 'resnext101_32x8d': resnext101_32x8d,\n",
        "                 'wide_resnet50_2': wide_resnet50_2, \n",
        "                 'wide_resnet101_2': wide_resnet101_2}\n",
        "\n",
        "class C19ResNet(nn.Module):\n",
        "    def __init__(self, pretrained=True, model='resnet18', RGB_input=True):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet_models[model](pretrained=pretrained)\n",
        "        self.fc = nn.Linear(in_features=self.backbone.fc.in_features, out_features=1)\n",
        "        self.RGB_input = RGB_input\n",
        "        if not RGB_input:\n",
        "            self.conv = nn.Conv2d(1, 3, 1)\n",
        "            self.conv.weight.data.fill_(1)\n",
        "            self.conv.bias.data.fill_(0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if not self.RGB_input:\n",
        "            x = self.conv(x)\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)        \n",
        "        x = self.backbone.relu(x)       \n",
        "        x = self.backbone.maxpool(x)  \n",
        "        \n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)        \n",
        "        x = self.backbone.layer3(x)        \n",
        "        x = self.backbone.layer4(x)\n",
        "        \n",
        "        x = self.backbone.avgpool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), self.backbone.fc.in_features)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86qqKTh2kqXT"
      },
      "source": [
        "# Model xception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydZ2VfVM6cUk"
      },
      "source": [
        "Xception pythorch implementation source: https://github.com/tstandley/Xception-PyTorch/blob/master/xception.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv8wyZ-4ko4D"
      },
      "source": [
        "\"\"\" \n",
        "Creates an Xception Model as defined in:\n",
        "Francois Chollet\n",
        "Xception: Deep Learning with Depthwise Separable Convolutions\n",
        "https://arxiv.org/pdf/1610.02357.pdf\n",
        "This weights ported from the Keras implementation. Achieves the following performance on the validation set:\n",
        "Loss:0.9173 Prec@1:78.892 Prec@5:94.292\n",
        "REMEMBER to set your image size to 3x299x299 for both test and validation\n",
        "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                  std=[0.5, 0.5, 0.5])\n",
        "The resize parameter of the validation transform should be 333, and make sure to center crop at 299x299\n",
        "\"\"\"\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "from torch.nn import init\n",
        "import torch\n",
        "\n",
        "__all__ = ['xception']\n",
        "\n",
        "model_urls = {\n",
        "    'xception':'https://www.dropbox.com/s/1hplpzet9d7dv29/xception-c0a72b38.pth.tar?dl=1'\n",
        "}\n",
        "\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "        # (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_filters, out_filters, reps, strides=1,start_with_relu=True,grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides!=1:\n",
        "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip=None\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        rep=[]\n",
        "\n",
        "        filters=in_filters\n",
        "        if grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "        \n",
        "        if not grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "\n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3,strides,1)) #? why? didn't it apply once in the first condition?\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "\n",
        "    def forward(self,inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "\n",
        "        x+=skip\n",
        "        return x\n",
        "\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    \"\"\"\n",
        "    Xception optimized for the ImageNet dataset, as specified in\n",
        "    https://arxiv.org/pdf/1610.02357.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=1000): # CHANGED from 1000 to 2\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            num_classes: number of classes\n",
        "        \"\"\"\n",
        "        super(Xception, self).__init__()\n",
        "\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 2, 0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        #do relu here\n",
        "\n",
        "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
        "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
        "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
        "\n",
        "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
        "        self.bn3 = nn.BatchNorm2d(1536)\n",
        "\n",
        "        #do relu here\n",
        "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
        "        self.bn4 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.fc = nn.Linear(2048, num_classes) # not using\n",
        "\n",
        "\n",
        "\n",
        "        #------- init weights --------\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "        #-----------------------------\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "        x = self.block8(x)\n",
        "        x = self.block9(x)\n",
        "        x = self.block10(x)\n",
        "        x = self.block11(x)\n",
        "        x = self.block12(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def xception(pretrained=False,**kwargs):\n",
        "    \"\"\"\n",
        "    Construct Xception.\n",
        "    \"\"\"\n",
        "\n",
        "    model = Xception(**kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['xception']))\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdRFm9T11SkW"
      },
      "source": [
        "covid xcpetion: all the xception layers are used with pretrained weights on imagenet, except for the last fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lq1vPxN1Kug"
      },
      "source": [
        "class C19Xception(nn.Module):\n",
        "    def __init__(self, pretrained=True, drop_out=False):\n",
        "        super().__init__()\n",
        "        self.backbone = xception(pretrained=pretrained)\n",
        "        self.fc = nn.Linear(in_features=self.backbone.fc.in_features, out_features=1)\n",
        "        self.drop_out = None\n",
        "        if drop_out:\n",
        "            self.drop_out = nn.drop_out(p=0.5)\n",
        "\n",
        "    \n",
        "    def forward(self, x, get_features=False):\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        \n",
        "        x = self.backbone.conv2(x)\n",
        "        x = self.backbone.bn2(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        \n",
        "        x = self.backbone.block1(x)\n",
        "        x = self.backbone.block2(x)\n",
        "        x = self.backbone.block3(x)\n",
        "        x = self.backbone.block4(x)\n",
        "        x = self.backbone.block5(x)\n",
        "        x = self.backbone.block6(x)\n",
        "        x = self.backbone.block7(x)\n",
        "        x = self.backbone.block8(x)\n",
        "        x = self.backbone.block9(x)\n",
        "        x = self.backbone.block10(x)\n",
        "        x = self.backbone.block11(x)\n",
        "        x = self.backbone.block12(x)\n",
        "        \n",
        "        x = self.backbone.conv3(x)\n",
        "        x = self.backbone.bn3(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        \n",
        "        x = self.backbone.conv4(x)\n",
        "        x = self.backbone.bn4(x)\n",
        "        x = self.backbone.relu(x)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if get_features:\n",
        "            return x\n",
        "            \n",
        "        if self.drop_out is not None:\n",
        "            x = self.drop_out(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX8EwCClDdDQ"
      },
      "source": [
        "C19Xception summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgLXMHgCaLN"
      },
      "source": [
        "model = C19Xception()\n",
        "print(model)\n",
        "print(\"Number of parameters:\")\n",
        "print(sum([p.numel() for p in model.parameters() if p.requires_grad]))\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akfDUminskf_"
      },
      "source": [
        "# Evaluating the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "469DclXGsntT"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "def calculate_score(y_true, y_pred, return_separates = False):\n",
        "  score = 6 * recall_score(y_true, y_pred, pos_label=1)\\\n",
        "    + 5 * recall_score(y_true, y_pred, pos_label=0)\\\n",
        "    + 3 * precision_score(y_true, y_pred, pos_label=1)\\\n",
        "    + 2 * precision_score(y_true, y_pred, pos_label=0)\n",
        "\n",
        "  if return_separates:\n",
        "    return score,\\\n",
        "    recall_score(y_true, y_pred, pos_label=1),\\\n",
        "    recall_score(y_true, y_pred, pos_label=0),\\\n",
        "    precision_score(y_true, y_pred, pos_label=1),\\\n",
        "    precision_score(y_true, y_pred, pos_label=0)\n",
        "  else:\n",
        "    return score\n",
        "\n",
        "\n",
        "# y_true = [0,0,0,0,0,1,1,1,1,1]\n",
        "# y_pred = [1,1,1,0,0,1,0,0,0,0]\n",
        "# y_wrong = [1,1,1,1,1,0,0,0,0,0]\n",
        "\n",
        "# print(\"sp {:.4f}, sn {:.4f}, pp {:.4f}, pn {:.4f}\".format(precision_score(y_true, y_pred, pos_label=1),\n",
        "#                                           precision_score(y_true, y_pred, pos_label=0),\n",
        "#                                           recall_score(y_true, y_pred, pos_label=1),\n",
        "#                                           recall_score(y_true, y_pred, pos_label=0)))\n",
        "\n",
        "# print(\"max score: {:.4f}, min score: {:.4f}, some score {:.4f}\".format(calculate_score(y_true, y_true),\n",
        "#                                                                       calculate_score(y_true, y_wrong),\n",
        "#                                                                       calculate_score(y_true, y_pred)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWYzA_8H8-4b"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u83Z8_TJpvTf"
      },
      "source": [
        "import time \n",
        "import copy\n",
        "import random\n",
        " \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def run_epoch(model, criterion, optimizer, phase):\n",
        "    all_pred_probs = torch.tensor([])\n",
        "    all_labels = torch.tensor([])\n",
        "    running_loss = 0\n",
        "\n",
        "    if phase == \"train\":\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    \n",
        "    for i, (inputs, labels) in tqdm(enumerate(dataloaders[phase]), \n",
        "                                    leave=False, \n",
        "                                    total=len(dataloaders[phase])):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze()\n",
        "            \n",
        "            loss = criterion(outputs, labels.float())\n",
        "            \n",
        "            if phase == \"train\":\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "        all_pred_probs = torch.cat((all_pred_probs, outputs.detach().clone().sigmoid().cpu()))\n",
        "        all_labels = torch.cat((all_labels, labels.detach().clone().cpu()))\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "        if (i % logging_steps[phase] == 0):# and (i>0):\n",
        "            avg_loss = running_loss / ((i+1) * batch_sizes[phase])  \n",
        "            \n",
        "            print(\"[{}]: {} | loss : {:.4f} | score : {:.4f}\"\n",
        "            .format(phase, i//logging_steps[phase], \n",
        "                    avg_loss, calculate_score(all_labels, (all_pred_probs > 0.5).type(torch.int8))))\n",
        "            \n",
        "    epoch_loss = running_loss / dataset_sizes[phase]\n",
        "    return epoch_loss, all_labels, all_pred_probs\n",
        "\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs, device=\"cuda\"):\n",
        "    since = time.time()\n",
        "\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "        print(\"Loading checkpoint\")\n",
        "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.cuda()\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        startE = checkpoint['epoch']\n",
        "    else:\n",
        "        startE = -1\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    epoch_loss, all_labels, all_pred_probs = run_epoch(model, criterion, optimizer, phase='test')\n",
        "    best_test_score, sp, sn, pp, pn = calculate_score(all_labels, (all_pred_probs > 0.5).type(torch.uint8), return_separates=True)\n",
        "\n",
        "\n",
        "    loss_history = {\"val\":[], \"train\":[]}\n",
        "    score_history = {\"val\":{'score':[], 'sp':[], 'sn':[], 'pp':[], 'pn':[]}, \n",
        "                     \"train\":{'score':[], 'sp':[], 'sn':[], 'pp':[], 'pn':[]}}\n",
        "    \n",
        "    for epoch in range(startE+1, num_epochs):\n",
        "        epoch_time = time.time()\n",
        "        print(\"epoch {}/{}\".format(epoch+1, num_epochs))\n",
        "\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            epoch_loss, all_labels, all_pred_probs = run_epoch(model, criterion, optimizer, phase)\n",
        "            score, sp, sn, pp, pn, = calculate_score(all_labels, (all_pred_probs > 0.5).type(torch.int8), return_separates=True)\n",
        "\n",
        "            \n",
        "            print(\"---[{}] Epoch {}/{} | time: {:.4f} | Loss : {:.4f} | Score: {:.4f} [sp:{:.4f}-sn:{:.4f}-pp:{:.4f}-pn:{:.4f}]\"\n",
        "            .format(phase, epoch+1, num_epochs, \n",
        "                    time.time()-epoch_time, epoch_loss, score, sp, sn, pp, pn))\n",
        "            loss_history[phase].append(epoch_loss)\n",
        "            score_history[phase]['score'].append(score)\n",
        "            score_history[phase]['sp'].append(sp)\n",
        "            score_history[phase]['sn'].append(sn)\n",
        "            score_history[phase]['pp'].append(pp)\n",
        "            score_history[phase]['pn'].append(pn)\n",
        "            \n",
        "        epoch_loss, all_labels, all_pred_probs = run_epoch(model, criterion, optimizer, phase='test')\n",
        "        test_score, sp, sn, pp, pn = calculate_score(all_labels, (all_pred_probs > 0.5).type(torch.int8), return_separates=True)\n",
        "        if test_score >= best_test_score:\n",
        "            print(\"************** best model update: Test score: {:.4f} [sp:{:.4f}-sn:{:.4f}-pp:{:.4f}-pn:{:.4f}] **********\".format(test_score, sp, sn, pp, pn))\n",
        "            best_test_score = test_score\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            \n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(), \n",
        "                    'best_model_state_dict': best_model_wts},\n",
        "                    CHECKPOINT_PATH)\n",
        "        \n",
        "        print(\"------ Epoch {}/{} finished. Best test score: {:.4f} ----------------------\"\n",
        "        .format(epoch+1, num_epochs, best_test_score))      \n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f\"training took {time_elapsed} seconds\")\n",
        "    print(f\"best score: {best_test_score}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, loss_history, score_history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLw0FO1aaVpC"
      },
      "source": [
        "# Call training\n",
        "\n",
        "We use weighted BCE loss to account for the imbalanced dataset. This approach gives us control over the sesitivitiy of the final model. We tested 10, 50, and 100 for the positive class loss weight and found 50 resulted in the best overall score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Qve8ASoT3A"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim import Adam\n",
        "\n",
        "lr = 3e-3 \n",
        "# lr = 1e-4\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = 'xception'\n",
        "pretrained = True\n",
        "drop_out = False\n",
        "BCE_pos_weight = 50\n",
        "\n",
        "train_batchsize = 32\n",
        "val_batchsize = 16\n",
        "test_batchsize = 16\n",
        "\n",
        "\n",
        "PATH = \"/content/gdrive/MyDrive/RTAI/Trained_models\"\n",
        "CLASS_NAME = model_name\\\n",
        "            + \"-epochs_\" + str(num_epochs)\\\n",
        "            + \"-pretrained_\" + str(pretrained)\\\n",
        "            + \"-batchsize_\" + str(train_batchsize)\\\n",
        "            + \"-posweight_\" + str(BCE_pos_weight)\\\n",
        "            + \"-lr_\" + str(lr)\\\n",
        "            + \"-drop_out_\" + str(drop_out)\n",
        "            #saves the model with the model name WARNING: overwrites previous model is the same model name exists\n",
        "model_path = os.path.join(PATH, CLASS_NAME)\n",
        "history_path = os.path.join(PATH, CLASS_NAME+\"-history.png\")\n",
        "details_history_path = os.path.join(PATH, CLASS_NAME+\"-details_history.png\")\n",
        "CHECKPOINT_PATH = os.path.join(PATH, CLASS_NAME+\"-Checkpoint\")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batchsize,\n",
        "                              shuffle=True, num_workers=4) # collate_fn=utils.collate_fn, pin_memory=True\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=val_batchsize,\n",
        "                              shuffle=True, num_workers=4) # collate_fn=utils.collate_fn, pin_memory=True                              \n",
        "test_dataloader = DataLoader(test_dataset, batch_size=test_batchsize, \n",
        "                             shuffle=False, num_workers=4) # collate_fn=utils.collate_fn, pin_memory=True\n",
        "\n",
        "\n",
        "dataloaders={'train': train_dataloader, \n",
        "             'val': val_dataloader,\n",
        "             'test': test_dataloader}\n",
        "\n",
        "logging_steps = {\n",
        "    \"train\": len(dataloaders[\"train\"]) // 10 + 1,\n",
        "    \"val\": len(dataloaders[\"val\"]) // 10 + 1,\n",
        "    \"test\": len(dataloaders[\"test\"]) // 10 + 1\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    \"train\": len(train_dataset),\n",
        "    \"val\": len(val_dataset),\n",
        "    \"test\": len(test_dataset)\n",
        "}\n",
        "\n",
        "batch_sizes = {\n",
        "    \"train\": train_batchsize,\n",
        "    \"val\": val_batchsize,\n",
        "    \"test\": test_batchsize\n",
        "}\n",
        "\n",
        "if (model_name == \"xception\"):\n",
        "    model = C19Xception(pretrained=pretrained)\n",
        "else:   \n",
        "    model = C19ResNet(model=model_name, pretrained=pretrained)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([BCE_pos_weight]).to(device),reduction='mean') \n",
        "# criterion = nn.BCEWithLogitsLoss() \n",
        "# can change pos_weight increasing pos_weight increases the sensitivity\n",
        "#  of the positive class\n",
        "# https://discuss.pytorch.org/t/weights-in-bcewithlogitsloss/27452\n",
        "\n",
        "print(\"train size:\", len(train_dataset))\n",
        "print(\"val size:\", len(val_dataset))\n",
        "print(\"test size:\", len(test_dataset))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwzNVdIjm3I5"
      },
      "source": [
        "model, loss_history, score_history = train_model(model, criterion, optimizer, num_epochs, device = device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epk8CozA86Xa"
      },
      "source": [
        "# # Unnecessary Check the alocated memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VubsnthZHKh"
      },
      "source": [
        "# To track allocated memory\n",
        "torch.cuda.memory_allocated(device=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBnFkcJ3AvVV"
      },
      "source": [
        "# Plotting the loss and accuracy history, and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlkqT4DbAux2"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(score_history['val']['sp'], label=\"validation\")\n",
        "plt.plot(score_history['train']['sp'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"sp\")\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(score_history['val']['sn'], label=\"validation\")\n",
        "plt.plot(score_history['train']['sn'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"sn\")\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(score_history['val']['pp'], label=\"validation\")\n",
        "plt.plot(score_history['train']['pp'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"pp\")\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(score_history['val']['pn'], label=\"validation\")\n",
        "plt.plot(score_history['train']['pn'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"pn\")\n",
        "plt.savefig(details_history_path)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(score_history['val']['score'], label=\"validation\")\n",
        "plt.plot(score_history['train']['score'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"score\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(loss_history['val'], label=\"validation\")\n",
        "plt.plot(loss_history['train'], label=\"train\")\n",
        "plt.legend()\n",
        "plt.title(\"loss\")\n",
        "plt.savefig(history_path)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Saving the model\n",
        "\n",
        "torch.save(model.state_dict(), model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXr_qm90CaXb"
      },
      "source": [
        "# Loading and evaluating the saved model\n",
        "\n",
        "We adjusted the probability threshold for the positive class to get the best competition score. \n",
        "\n",
        "Our best trained model's performance on the test set: \n",
        "\n",
        "-- *15.960075 (sp: 1, sn: 0.995, pp: 0.995025, pn: 1)*\n",
        "\n",
        "its performance on the competition set: \n",
        "\n",
        "-- *14.94 (sp: 0.88, pp: 1, sn: 0.99 pn: 0.86)* [changed ?] \n",
        "    \n",
        "By reducing the positive class threshold to 0.35 model's performance on the test set became:\n",
        "\n",
        "-- *15.762621 (sp:1, sn:0.97, pp: 0.970874 pn: 1)* \n",
        "\n",
        "its performance on the competition set: \n",
        "\n",
        "-- *15.30 (sp: 0.93, pp: 0.99, sn: 0.98, pn: 0.93)* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaxal7X1CZlo"
      },
      "source": [
        "model_name = 'xception'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "PATH = \"/content/gdrive/MyDrive/RTAI/Trained_models\"\n",
        "# CLASS_NAME = \"xception-epochs_50-pretrained_True-batchsize_32-posweight_10\" #first submission\n",
        "# CLASS_NAME = \"xception-epochs_30-pretrained_True-batchsize_32-posweight_50-lr_0.003-drop_out_False\" #second submission\n",
        "CLASS_NAME = \"xception-epochs_10-pretrained_True-batchsize_32-posweight_50-lr_0.003\" #third & fourth & sixth submission\n",
        "# CLASS_NAME = \"xception-epochs_30-pretrained_True-batchsize_32-posweight_100\" # fifth submission\n",
        "# CLASS_NAME = \"xception-epochs_10-pretrained_True-batchsize_32-posweight_10-lr_0.003-drop_out_True\"\n",
        "\n",
        "threshold = 0.35\n",
        "\n",
        "model_path = os.path.join(PATH, CLASS_NAME)\n",
        "print(model_path)\n",
        "# model = C19ResNet(model=model_name, pretrained=False)\n",
        "model = C19Xception(pretrained=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "print(\"loaded\")\n",
        "\n",
        "epoch_loss, all_labels, all_pred_probs = run_epoch(model, criterion, optimizer, phase='test')\n",
        "test_score, sp, sn, pp, pn = calculate_score(all_labels, (all_pred_probs > threshold).type(torch.uint8), return_separates=True)\n",
        "\n",
        "print(\"Loaded model test score: {:.6f}, sp: {:.6f}, sn: {:.6f}, pp:{:.6f}, pn:{:.6f}\".format(test_score, sp, sn, pp, pn))\n",
        "n, bins, patches = plt.hist(all_pred_probs, 100, facecolor='blue', alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhxCidMiOhId"
      },
      "source": [
        "# get competition images output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76EcM6kJV25X"
      },
      "source": [
        "L = os.listdir(competition_test_path)\n",
        "L.sort(key=lambda x:int(os.path.splitext(x)[0]))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "preds = []\n",
        "for p in tqdm(L):\n",
        "    im_path = os.path.join(competition_test_path, p)\n",
        "    image = Image.open(im_path).convert(\"RGB\")\n",
        "    image_tensor = test_transform(image)\n",
        "    image_tensor = torch.unsqueeze(image_tensor, 0).to(device)\n",
        "\n",
        "    preds.append(model.forward(image_tensor).detach().clone().squeeze())\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnHOCkhyrSX4"
      },
      "source": [
        "probs = torch.tensor(preds).sigmoid()\n",
        "\n",
        "print(\"probs\", probs)\n",
        "print(\"probs mean\", torch.mean(probs))\n",
        "print(\"probs sd\", torch.std(probs))\n",
        "n, bins, patches = plt.hist(probs, 100, facecolor='blue', alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "for p in probs>threshold:\n",
        "    print(int(p))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}